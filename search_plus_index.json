{"./":{"url":"./","title":"序言","keywords":"","body":"docker-notes docker学习笔记 前言 序言 安装与配置 安装Docker 基本概念 Docker架构图 Docker常用命令原理图 Dockerfile使用说明 核心原理 namespace cgroup 源码分析 Docker Client Docker Daemon Docker Server Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-09 19:58:04 "},"install/install-docker.html":{"url":"install/install-docker.html","title":"安装Docker","keywords":"","body":"1. CentOS 安装Docker 建议使用centos7 1.1. 安装Docker 1.1.1. 卸载旧版本 旧版本的Docker命名为docker或docker-engine，如果有安装旧版本，先卸载旧版本 $ sudo yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 1.1.2. 使用仓库安装 1、安装yum-utils、device-mapper-persistent-data、lvm2 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 2、添加软件源 $ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 1.1.3. 安装Docker 安装最新版本的Docker CE。 $ sudo yum install -y docker-ce 1.1.4. 启动Docker # 启动Docker $ sudo systemctl start docker # 运行容器 $ sudo docker run hello-world 1.2. 安装指定版本Docker 1、列出可安装版本 $ yum list docker-ce --showduplicates | sort -r docker-ce.x86_64 18.03.0.ce-1.el7.centos docker-ce-stable 2、安装指定版本 例如：docker-ce-18.03.0.ce $ sudo yum install docker-ce- 1.3. 升级Docker 依据1.2的方法选择指定版本安装。 1.4. 卸载Docker # 卸载Docker $ sudo yum remove docker-ce # 清理镜像、容器、存储卷等 $ sudo rm -rf /var/lib/docker 2. Ubuntu 安装Docker 2.1. 安装Docker 2.1.1. 卸载旧版本 旧版本的Docker命名为docker或docker-engine，如果有安装旧版本，先卸载旧版本 sudo apt-get remove docker docker-engine docker.io 2.1.2. 使用仓库安装 1、升级apt sudo apt-get update 2、允许apt使用https sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ software-properties-common 3、添加Docker 官方的GPG密钥 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 4、添加Docker软件源 sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 2.1.3. 安装Docker # update sudo apt-get update # install docker sudo apt-get install docker-ce 2.1.4. 启动Docker # 设置为开机启动 sudo systemctl enable docker # 启动docker sudo systemctl start docker 2.2. 安装指定版本Docker 1、列出仓库的可安装版本，apt-cache madison docker-ce。 # apt-cache madison docker-ce docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages docker-ce | 18.03.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages 2、指定版本安装 例如：docker-ce=18.03.0~ce-0~ubuntu sudo apt-get install docker-ce= 2.3. 升级Docker # 更新源 sudo apt-get update # 依据上述方法，指定版本安装 2.4. 卸载Docker # 卸载 docker ce sudo apt-get purge docker-ce # 清理镜像、容器、存储卷等 sudo rm -rf /var/lib/docker 3. 离线rpm包安装Docker 3.1. 下载docker rpm包 rpm包地址：https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/ 下载指定版本的containerd.io、docker-ce、docker-ce-cli wget https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm wget https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/docker-ce-18.09.9-3.el7.x86_64.rpm wget https://mirrors.aliyun.com/docker-ce/linux/centos/7/x86_64/stable/Packages/docker-ce-cli-18.09.9-3.el7.x86_64.rpm 下载container-selinux 地址：http://mirror.centos.org/centos/7/extras/x86_64/Packages/ wget http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.107-3.el7.noarch.rpm 3.2. 安装rpm包 # container-selinux rpm -ivh container-selinux*.rpm # containerd.io rpm -ivh containerd.io*.rpm # docker-ce rpm -ivh docker-ce*.rpm # docker-ce-cli rpm -ivh docker-ce-cli*.rpm 3.3. 启动docker服务 # 启动 systemctl start docker # 查看状态 systemctl status docker 文章参考： https://docs.docker.com/install/linux/docker-ce/centos/ https://docs.docker.com/install/linux/docker-ce/ubuntu/ Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"basics/docker-architecture.html":{"url":"basics/docker-architecture.html","title":"Docker架构图","keywords":"","body":"1. Docker的总架构图 docker是一个C/S模式的架构，后端是一个松耦合架构，模块各司其职。 用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求； Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储； 当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境； 当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。 libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。 2. Docker各模块组件分析 2.1. Docker Client[发起请求] Docker Client是和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker（类似可执行脚本的命令），docker命令后接参数的形式来实现一个完整的请求命令（例如docker images，docker为命令不可变，images为参数可变）。 Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp://host:port，unix://path_to_socket和fd://socketfd。 Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。[一次完整的请求：发送请求→处理请求→返回结果]，与传统的C/S架构请求流程并无不同。 2.2. Docker Daemon[后台守护进程] Docker Daemon的架构图 2.2.1. Docker Server[调度分发请求] Docker Server的架构图 Docker Server相当于C/S架构的服务端。功能为接受并调度分发Docker Client发送的请求。接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 在Docker的启动过程中，通过包gorilla/mux，创建了一个mux.Router，提供请求的路由功能。在Golang中，gorilla/mux是一个强大的URL路由器以及调度分发器。该mux.Router中添加了众多的路由项，每一个路由项由HTTP请求方法（PUT、POST、GET或DELETE）、URL、Handler三部分组成。 创建完mux.Router之后，Docker将Server的监听地址以及mux.Router作为参数，创建一个httpSrv=http.Server{}，最终执行httpSrv.Serve()为请求服务。 在Server的服务过程中，Server在listener上接受Docker Client的访问请求，并创建一个全新的goroutine来服务该请求。在goroutine中，首先读取请求内容，然后做解析工作，接着找到相应的路由项，随后调用相应的Handler来处理该请求，最后Handler处理完请求之后回复该请求。 2.2.2. Engine Engine是Docker架构中的运行引擎，同时也Docker运行的核心模块。它扮演Docker container存储仓库的角色，并且通过执行job的方式来操纵管理这些容器。 在Engine数据结构的设计与实现过程中，有一个handler对象。该handler对象存储的都是关于众多特定job的handler处理访问。举例说明，Engine的handler对象中有一项为：{\"create\": daemon.ContainerCreate,}，则说明当名为\"create\"的job在运行时，执行的是daemon.ContainerCreate的handler。 2.2.3. Job 一个Job可以认为是Docker架构中Engine内部最基本的工作执行单元。Docker可以做的每一项工作，都可以抽象为一个job。例如：在容器内部运行一个进程，这是一个job；创建一个新的容器，这是一个job。Docker Server的运行过程也是一个job，名为serveapi。 Job的设计者，把Job设计得与Unix进程相仿。比如说：Job有一个名称，有参数，有环境变量，有标准的输入输出，有错误处理，有返回状态等。 2.3. Docker Registry[镜像注册中心] Docker Registry是一个存储容器镜像的仓库（注册中心），可理解为云端镜像仓库，按repository来分类，docker pull 按照[repository]:[tag]来精确定义一个image。 在Docker的运行过程中，Docker Daemon会与Docker Registry通信，并实现搜索镜像、下载镜像、上传镜像三个功能，这三个功能对应的job名称分别为\"search\"，\"pull\" 与 \"push\"。 可分为公有仓库（docker hub）和私有仓库。 2.4. Graph[docker内部数据库] Graph的架构图 2.4.1. Repository 已下载镜像的保管者（包括下载镜像和dockerfile构建的镜像）。 一个repository表示某类镜像的仓库（例如Ubuntu），同一个repository内的镜像用tag来区分（表示同一类镜像的不同标签或版本）。一个registry包含多个repository，一个repository包含同类型的多个image。 镜像的存储类型有aufs，devicemapper,Btrfs，Vfs等。其中centos系统使用devicemapper的存储类型。 同时在Graph的本地目录中，关于每一个的容器镜像，具体存储的信息有：该容器镜像的元数据，容器镜像的大小信息，以及该容器镜像所代表的具体rootfs。 2.4.2. GraphDB 已下载容器镜像之间关系的记录者。 GraphDB是一个构建在SQLite之上的小型图数据库，实现了节点的命名以及节点之间关联关系的记录 2.5. Driver[执行部分] Driver是Docker架构中的驱动模块。通过Driver驱动，Docker可以实现对Docker容器执行环境的定制。即Graph负责镜像的存储，Driver负责容器的执行。 2.5.1. graphdriver graphdriver架构图 graphdriver主要用于完成容器镜像的管理，包括存储与获取。 存储：docker pull下载的镜像由graphdriver存储到本地的指定目录（Graph中）。 获取：docker run（create）用镜像来创建容器的时候由graphdriver到本地Graph中获取镜像。 2.5.2. networkdriver networkdriver的架构图 networkdriver的用途是完成Docker容器网络环境的配置，其中包括 Docker启动时为Docker环境创建网桥； Docker容器创建时为其创建专属虚拟网卡设备； Docker容器分配IP、端口并与宿主机做端口映射，设置容器防火墙策略等。 2.5.3. execdriver execdriver的架构图 execdriver作为Docker容器的执行驱动，负责创建容器运行命名空间，负责容器资源使用的统计与限制，负责容器内部进程的真正运行等。 现在execdriver默认使用native驱动，不依赖于LXC。 2.6. libcontainer[函数库] libcontainer的架构图 libcontainer是Docker架构中一个使用Go语言设计实现的库，设计初衷是希望该库可以不依靠任何依赖，直接访问内核中与容器相关的API。 Docker可以直接调用libcontainer，而最终操纵容器的namespace、cgroups、apparmor、网络设备以及防火墙规则等。 libcontainer提供了一整套标准的接口来满足上层对容器管理的需求。或者说，libcontainer屏蔽了Docker上层对容器的直接管理。 2.7. docker container[服务交付的最终形式] container架构 Docker container（Docker容器）是Docker架构中服务交付的最终体现形式。 Docker按照用户的需求与指令，订制相应的Docker容器： 用户通过指定容器镜像，使得Docker容器可以自定义rootfs等文件系统； 用户通过指定计算资源的配额，使得Docker容器使用指定的计算资源； 用户通过配置网络及其安全策略，使得Docker容器拥有独立且安全的网络环境； 用户通过指定运行的命令，使得Docker容器执行指定的工作。 参考文章： 《Docker源码分析》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"basics/docker-commands-principle.html":{"url":"basics/docker-commands-principle.html","title":"Docker常用命令原理图","keywords":"","body":"1. 基本概念 1.1. image layer（镜像层） 镜像可以看成是由多个镜像层叠加起来的一个文件系统，镜像层也可以简单理解为一个基本的镜像，而每个镜像层之间通过指针的形式进行叠加。 图片 - 1 根据上图，镜像层的主要组成部分包括镜像层id，镜像层指针【指向父层】，元数据【layer metadata】包含了docker构建和运行的信息还有父层的层次信息。 只读层和读写层【top layer】的组成部分基本一致。同时读写层可以转换成只读层【docker commit操作实现】 1.2. image（镜像）---【只读层的集合】 1、镜像是一堆只读层的统一视角，除了最底层没有指向外，每一层都指向它的父层，统一文件系统（union file system）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。而每一层都是不可写的，就是只读层。 图片 - 2.1 1.3. container（容器）---【一层读写层+多层只读层】 1、容器和镜像的区别在于容器的最上面一层是读写层【top layer】，而这边并没有区分容器是否在运行。运行状态的容器【running container】即一个可读写的文件系统【静态容器】+隔离的进程空间和其中的进程。 隔离的进程空间中的进程可以对该读写层进行增删改，其运行状态容器的进程操作都作用在该读写层上。每个容器只能有一个进程隔离空间。 图片 - 3.2 2. Docker常用命令原理图概览： 3. Docker常用命令说明 3.1. 标识说明 3.1.1. image---（统一只读文件系统） 图片 - 4.1.1 3.1.2. 静态容器【未运行的容器】---（统一可读写文件系统） 图片 - 4.1.2 3.1.3. 动态容器【running container】---（进程空间（包括进程）+统一可读写文件系统） 图片 - 4.1.3 3.2. 命令说明 3.2.1. docker生命周期相关命令: 3.2.1.1. docker create {image-id} 图片 - 4.2.1.1 即为只读文件系统添加一层可读写层【top layer】，生成可读写文件系统，该命令状态下容器为静态容器，并没有运行。 3.2.1.2. docker start（restart） {container-id} docker stop即为docker start的逆过程 图片 - 4.2.1.2 即为可读写文件系统添加一个进程空间【包括进程】，生成动态容器【running container】 3.2.1.3. docker run {image-id} 图片 - 4.2.1.3 docker run=docker create+docker start 类似流程如下 ： 图片 - 4.2.1.3.1 3.2.1.4. docker stop {container-id} 图片 - 4.2.1.4 向运行的容器中发一个SIGTERM的信号，然后停止所有的进程。即为docker start的逆过程。 3.2.1.5. docker kill {container-id} 图片 - 4.2.1.5 docker kill向容器发送不友好的SIGKILL的信号，相当于快速强制关闭容器，与docker stop的区别在于docker stop是正常关闭，先发SIGTERM信号，清理进程，再发SIGKILL信号退出。 3.2.1.6. docker pause {container-id} docker unpause为逆过程---比较少使用 图片 - 4.2.1.6 暂停容器中的所有进程，使用cgroup的freezer顺序暂停容器里的所有进程，docker unpause为逆过程即恢复所有进程。比较少使用。 3.2.1.7. docker commit {container-id} 图片 - 4.2.1.7 图片 - 4.2.1.7.2 把容器的可读写层转化成只读层，即从容器状态【可读写文件系统】变为镜像状态【只读文件系统】，可理解为【固化】。 3.2.1.8. docker build 图片 - 4.2.1.8.1 图片 - 4.2.1.8.2 docker build=docker run【运行容器】+【进程修改数据】+docker commit【固化数据】，不断循环直至生成所需镜像。 循环一次便会形成新的层（镜像）【原镜像层+已固化的可读写层】 docker build 一般作用在dockerfile文件上。 3.2.2. docker查询类命令 查询对象：①image，②container，③image/container中的数据，④系统信息[容器数，镜像数及其他] 3.2.2.1. Image 1、docker images 图片 - 4.2.2.1.1 docker images 列出当前镜像【以顶层镜像id来表示整个完整镜像】，每个顶层镜像下面隐藏多个镜像层。 2、docker images -a 图片 - 4.2.2.1.2 docker images -a列出所有镜像层【排序以每个顶层镜像id为首后接该镜像下的所有镜像层】，依次列出每个镜像的所有镜像层。 3、docker history {image-id} 图片 - 4.2.2.1.3 docker history 列出该镜像id下的所有历史镜像。 3.2.2.2. Container 1、docker ps 图片 - 4.2.2.2.1 列出所有运行的容器【running container】 2、docker ps -a 图片 - 4.2.2.2.2 列出所有容器，包括静态容器【未运行的容器】和动态容器【running container】 3.2.2.3. Info 1、docker inspect {container-id} or {image-id} 图片 - 4.2.2.3.1 提取出容器或镜像最顶层的元数据。 2、docker info 显示 Docker 系统信息，包括镜像和容器数。 3.2.3. docker操作类命令： 3.2.3.1. docker rm {container-id} 图片 - 4.2.3.1 docker rm会移除镜像，该命令只能对静态容器【非运行状态】进行操作。 通过docker rm -f {container-id}的-f （force）参数可以强制删除运行状态的容器【running container】。 3.2.3.2. docker rmi {image-id} 图片 - 4.2.3.2 3.2.3.3. docker exec {running-container-id} 图片 - 4.2.3.3 docker exec会在运行状态的容器中执行一个新的进程。 3.2.3.4. docker export {container-id} 图片 - 4.2.3.4 docker export命令创建一个tar文件，并且移除了元数据和不必要的层，将多个层整合成了一个层，只保存了当前统一视角看到的内容。 参考文章： http://merrigrove.blogspot.com/2015/10/visualizing-docker-containers-and-images.html Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"basics/dockerfile-usage.html":{"url":"basics/dockerfile-usage.html","title":"Dockerfile使用说明","keywords":"","body":"1. Dockerfile的说明 dockerfile指令忽略大小写，建议大写，#作为注释，每行只支持一条指令，指令可以带多个参数。 dockerfile指令分为构建指令和设置指令。 构建指令：用于构建image，其指定的操作不会在运行image的容器中执行。 设置指令：用于设置image的属性，其指定的操作会在运行image的容器中执行。 2. Dockerfile指令说明 2.1. FROM（指定基础镜像）[构建指令] 该命令用来指定基础镜像，在基础镜像的基础上修改数据从而构建新的镜像。基础镜像可以是本地仓库也可以是远程仓库。 指令有两种格式： FROM image 【默认为latest版本】 FROM image:tag 【指定版本】 2.2. MAINTAINER（镜像创建者信息）[构建指令] 将镜像制作者（维护者）的信息写入image中，执行docker inspect时会输出该信息。 格式：MAINTAINER name MAINTAINER命令已废弃，可使用maintainer label的方式。 LABEL maintainer=\"SvenDowideit@home.org.au\" 2.3. RUN（安装软件用）[构建指令] RUN可以运行任何被基础镜像支持的命令（即在基础镜像上执行一个进程），可以使用多条RUN指令，指令较长可以使用\\来换行。 指令有两种格式： RUN command (the command is run in a shell - /bin/sh -c) RUN [\"executable\", \"param1\", \"param2\" ... ] (exec form) 指定使用其他终端实现，使用exec执行。 例子：RUN[\"/bin/bash\",\"-c\",\"echo hello\"] 2.4. CMD（设置container启动时执行的操作）[设置指令] 用于容器启动时的指定操作，可以是自定义脚本或命令，只执行一次，多个默认执行最后一个。 指令有三种格式： CMD [\"executable\",\"param1\",\"param2\"] (like an exec, this is the preferred form) 运行一个可执行文件并提供参数。 CMD command param1 param2 (as a shell) 直接执行shell命令，默认以/bin/sh -c执行。 CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT) 和ENTRYPOINT配合使用，只作为完整命令的参数部分。 2.5. ENTRYPOINT（设置container启动时执行的操作）[设置指令] 指定容器启动时执行的命令，若多次设置只执行最后一次。 ENTRYPOINT翻译为“进入点”，它的功能可以让容器表现得像一个可执行程序一样。 例子：ENTRYPOINT [\"/bin/echo\"] ，那么docker build出来的镜像以后的容器功能就像一个/bin/echo程序，docker run -it imageecho “this is a test”，就会输出对应的字符串。这个imageecho镜像对应的容器表现出来的功能就像一个echo程序一样。 指令有两种格式： ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (like an exec, the preferred form) 和CMD配合使用，CMD则作为完整命令的参数部分，ENTRYPOINT以JSON格式指定执行的命令部分。CMD可以为ENTRYPOINT提供可变参数，不需要变动的参数可以写在ENTRYPOINT里面。 例子： ENTRYPOINT [\"/usr/bin/ls\",\"-a\"] CMD [\"-l\"] ENTRYPOINT command param1 param2 (as a shell) 独自使用，即和CMD类似，如果CMD也是个完整命令[CMD command param1 param2 (as a shell) ]，那么会相互覆盖，只执行最后一个CMD或ENTRYPOINT。 例子：ENTRYPOINT ls -l 2.6. USER（设置container容器启动的登录用户）[设置指令] 设置启动容器的用户，默认为root用户。 格式：USER daemon 2.7. EXPOSE（指定容器需要映射到宿主机的端口）[设置指令] 该指令会将容器中的端口映射为宿主机中的端口[确保宿主机的端口号没有被使用]。通过宿主机IP和映射后的端口即可访问容器[避免每次运行容器时IP随机生成不固定的问题]。前提是EXPOSE设置映射端口，运行容器时加上-p参数指定EXPOSE设置的端口。EXPOSE可以设置多个端口号，相应地运行容器配套多次使用-p参数。可以通过docker port +容器需要映射的端口号和容器ID来参考宿主机的映射端口。 格式：EXPOSE port [port...] 2.8. ENV（用于设置环境变量）[构建指令] 在image中设置环境变量[以键值对的形式]，设置之后RUN命令可以使用该环境变量，在容器启动后也可以通过docker inspect查看环境变量或者通过 docker run --env key=value设置或修改环境变量。 格式：ENV key value 例子：ENV JAVA_HOME /path/to/java/dirent 2.9. ARG（用于设置变量）[构建指令] ARG定义一个默认参数，可以在dockerfile中引用。构建阶段可以通过docker build --build-arg =参数向dockerfile文件中传入参数。 ARG [=] # 可以搭配ENV使用 ENV env_name ${arg_name} 示例： docker build --build-arg user=what_user . 2.10. ADD（从src复制文件到container的dest路径）[构建指令] 复制指定的src到容器中的dest，其中src是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url。dest 是container中的绝对路径。所有拷贝到container中的文件和文件夹权限为0755，uid和gid为0。 如果src是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录； 如果src文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）； 如果src是文件且dest中不使用斜杠结束，则会将dest视为文件，src的内容会写入dest； 如果src是文件且dest中使用斜杠结束，则会src文件拷贝到dest目录下。 格式：ADD src dest 为避免 ADD命令带来的未知风险和复杂性，可以使用COPY命令替代ADD命令 2.11. COPY（复制文件） 复制本地主机的src为容器中的dest，目标路径不存在时会自动创建。 格式：COPY src dest 2.12. VOLUME（指定挂载点）[设置指令] 创建一个可以从本地主机或其他容器挂载的挂载点，使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用也可以被其他容器使用。 格式：VOLUME [\"mountpoint\"] 其他容器使用共享数据卷：docker run -t -i -rm -volumes-from container1 image2 bash [container1为第一个容器的ID，image2为第二个容器运行image的名字。] 2.13. WORKDIR（切换目录）[设置指令] 相当于cd命令，可以多次切换目录，为RUN,CMD,ENTRYPOINT配置工作目录。可以使用多个WORKDIR的命令，后续命令如果是相对路径则是在上一级路径的基础上执行[类似cd的功能]。 格式：WORKDIR /path/to/workdir 2.14. ONBUILD（在子镜像中执行） 当所创建的镜像作为其他新创建镜像的基础镜像时执行的操作命令，即在创建本镜像时不运行，当作为别人的基础镜像时再在构建时运行（可认为基础镜像为父镜像，而该命令即在它的子镜像构建时运行，相当于在子镜像构建时多加了一些命令）。 格式：ONBUILD Dockerfile关键字 3. dockerfile示例 最佳实践 镜像可以分为三层：系统基础镜像、业务基础镜像、业务镜像。 尽量将不变的镜像操作放dockerfile前面。 一类RUN命令操作可以通过\\和&&方式组合成一条RUN命令。 dockerfile尽量清晰简洁。 文件目录 ./ |-- Dockerfile |-- docker-entrypoint.sh |-- dumb-init |-- conf # 配置文件路径 | `-- app_conf.py |-- pkg # 安装包路径 | `-- install.tar.gz |-- run.sh # 启动脚本 dockerfile示例 FROM centos:latest LABEL maintainer=\"xxx@xxx.com\" ARG APP=appname ENV APP ${APP} # copy and install app COPY conf/app_conf.py /usr/local/app/app_conf/app_conf.py COPY pkg/${APP}-*-install.tar.gz /data/${APP}-install.tar.gz RUN mkdir -p /data/${APP} \\ && tar -zxvf /data/${APP}-install.tar.gz -C /data/${APP} \\ && cd /data/${APP}/${APP}* \\ && ./install.sh WORKDIR /usr/local/app/ # init COPY dumb-init /usr/bin/dumb-init COPY docker-entrypoint.sh /docker-entrypoint.sh ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\",\"/docker-entrypoint.sh\"] COPY run.sh /run.sh RUN chmod +x /run.sh CMD [\"/run.sh\"] 4. docker build 指定dockerfile文件构建 默认不指定dockerfile文件名，则读取指定路径的Dockerfile docker build -t -f docker build --help docker build --help Usage: docker build [OPTIONS] PATH | URL | - Build an image from a Dockerfile Options: --add-host list Add a custom host-to-IP mapping (host:ip) --build-arg list Set build-time variables --cache-from strings Images to consider as cache sources --cgroup-parent string Optional parent cgroup for the container --compress Compress the build context using gzip --cpu-period int Limit the CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit the CPU CFS (Completely Fair Scheduler) quota -c, --cpu-shares int CPU shares (relative weight) --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --disable-content-trust Skip image verification (default true) -f, --file string Name of the Dockerfile (Default is 'PATH/Dockerfile') --force-rm Always remove intermediate containers --iidfile string Write the image ID to the file --isolation string Container isolation technology --label list Set metadata for an image -m, --memory bytes Memory limit --memory-swap bytes Swap limit equal to memory plus swap: '-1' to enable unlimited swap --network string Set the networking mode for the RUN instructions during build (default \"default\") --no-cache Do not use cache when building the image --pull Always attempt to pull a newer version of the image -q, --quiet Suppress the build output and print image ID on success --rm Remove intermediate containers after a successful build (default true) --security-opt strings Security options --shm-size bytes Size of /dev/shm -t, --tag list Name and optionally a tag in the 'name:tag' format --target string Set the target build stage to build. --ulimit ulimit Ulimit options (default []) 参考： https://docs.docker.com/engine/reference/builder/ Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"principle/namespace.html":{"url":"principle/namespace.html","title":"namespace","keywords":"","body":"1. Namespace简介 Namespace是内核的一个功能，用来给进程隔离一系列系统资源（视图隔离）。 2. 类别 namespace类别 隔离资源 系统调用参数 内核版本 Docker中的例子 Mount namespace 挂载点 CLONE_NEWNS 2.4.19 独立的挂载点 UTS Namespace hostname和domainname CLONE_NEWUTS 2.6.19 独立的hostname IPC Namespace System V IPC, POSIX message queues CLONE_NEWIPC 2.6.19 PID Namespace 进程ID CLONE_NEWPID 2.6.24 容器进程PID为1 Network Namespace 网络设备，端口，网络栈 CLONE_NEWNET 2.6.24 独立的网络和端口 User Namespace 用户ID，group ID CLONE_NEWUSER 3.8 独立的用户ID 3. Namespace API API 说明 clone() 基于某namespace创建新进程，他们的子进程也包含在该namespace中 unshare() 将进程移出某个namespace setns() 将进程加入某个namespace 4. Namespace相关命令 4.1. unshare 让进程进入一个新的namespace。 $ unshare --help 用法： unshare [options] [...] Run a program with some namespaces unshared from the parent. 选项： -m, --mount unshare mounts namespace -u, --uts unshare UTS namespace (hostname etc) -i, --ipc unshare System V IPC namespace -n, --net unshare network namespace -p, --pid unshare pid namespace -U, --user unshare user namespace -f, --fork fork before launching --mount-proc[=] mount proc filesystem first (implies --mount) -r, --map-root-user map current user to root (implies --user) --propagation modify mount propagation in mount namespace -s, --setgroups allow|deny control the setgroups syscall in user namespaces -h, --help 显示此帮助并退出 -V, --version 输出版本信息并退出 更多信息请参阅 unshare(1)。 示例： 4.2. nsenter 进入某个namespace下运行某个进程。例如：docker exec -it bash。 $ nsenter --help 用法： nsenter [options] [...] Run a program with namespaces of other processes. 选项： -t, --target 要获取名字空间的目标进程 -m, --mount[=] enter mount namespace -u, --uts[=] enter UTS namespace (hostname etc) -i, --ipc[=] enter System V IPC namespace -n, --net[=] enter network namespace -p, --pid[=] enter pid namespace -U, --user[=] enter user namespace -S, --setuid set uid in entered namespace -G, --setgid set gid in entered namespace --preserve-credentials do not touch uids or gids -r, --root[=] set the root directory -w, --wd[=] set the working directory -F, --no-fork 执行 前不 fork -Z, --follow-context set SELinux context according to --target PID -h, --help 显示此帮助并退出 -V, --version 输出版本信息并退出 更多信息请参阅 nsenter(1)。 5. namespace细分 5.1. Mount Namespace Mount Namespace可以用了隔离各个进程的挂载点视图。不同的namespace中文件系统层次不一样，在其中调用mount和umount仅影响当前namespace。 5.2. Network Namespace Network Namespace用来隔离网络设备，IP地址端口等网络栈。容器内可以绑定自己的端口，在宿主机建立网桥，就可以实现容器之间的通信。 ip netns 命令用来管理 network namespace。 # ip netns help Usage: ip netns list ip netns add NAME ip netns set NAME NETNSID ip [-all] netns delete [NAME] ip netns identify [PID] ip netns pids NAME ip [-all] netns exec [NAME] cmd ... ip netns monitor ip netns list-id 示例： 模拟创建docker0及docker网络 1、创建lxcbr0，相当于docker0 # 添加一个网桥lxcbr0,相当于docker0 brctl addbr lxcbr0 brctl stp lxcbr0 off ifconfig lxcbr0 192.168.10.1/24 up # 配置网桥IP地址 # 查看网桥 # ifconfig lxcbr0: flags=4163 mtu 1500 inet 192.168.10.1 netmask 255.255.255.0 broadcast 192.168.10.255 inet6 fe80::94cb:eaff:fe48:cdd5 prefixlen 64 scopeid 0x20 ether 96:cb:ea:48:cd:d5 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5 bytes 426 (426.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 添加网络命名空间 # 添加网络命名空间ns1 ip netns add ns1 # 激活namespace中的loopback，即127.0.0.1 ip netns exec ns1 ip link set dev lo up 3、添加虚拟网卡 # 增加一个pair虚拟网卡，注意其中的veth类型，其中一个网卡要按进容器中 ip link add veth-ns1 type veth peer name lxcbr0.1 # 把 veth-ns1 按到namespace ns1中，这样容器中就会有一个新的网卡了 ip link set veth-ns1 netns ns1 4、修改容器内网卡为eth0，并分配IP # 把容器里的 veth-ns1改名为 eth0 （容器外会冲突，容器内就不会了） ip netns exec ns1 ip link set dev veth-ns1 name eth0 # 为容器中的网卡分配一个IP地址，并激活它 ip netns exec ns1 ifconfig eth0 192.168.10.11/24 up 5、将lxcbr0.1添加上网桥 # 上面我们把veth-ns1这个网卡按到了容器中，然后我们要把lxcbr0.1添加上网桥上 brctl addif lxcbr0 lxcbr0.1 6、添加路由 # 为容器增加一个路由规则，让容器可以访问外面的网络 ip netns exec ns1 ip route add default via 192.168.10.1 7、添加nameserver # 在/etc/netns下创建network namespce名称为ns1的目录， # 然后为这个namespace设置resolv.conf，这样，容器内就可以访问域名了 mkdir -p /etc/netns/ns1 echo \"nameserver 8.8.8.8\" > /etc/netns/ns1/resolv.conf 8、查看网络空间内的网络配置 # 进入网络命名空间 ip netns exec ns1 bash # 查看网络配置 ifconfig eth0: flags=4099 mtu 1500 inet 192.168.10.11 netmask 255.255.255.0 broadcast 192.168.10.255 ether 2a:0c:a8:b7:bc:32 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73 mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10 loop txqueuelen 1000 (Local Loopback) RX packets 4 bytes 240 (240.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 4 bytes 240 (240.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 参考： https://lwn.net/Articles/531114/ https://coolshell.cn/articles/17010.html https://coolshell.cn/articles/17029.html Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-05 15:43:19 "},"principle/cgroup.html":{"url":"principle/cgroup.html","title":"cgroup","keywords":"","body":"1. cgroup简介 Linux Cgroup提供了对一组进程及将来子进程的资源限制的能力。资源包括：CPU、内存、存储、网络等。通过Cgroup可以限制某个进程的资源占用，并监控进程的统计信息。 2. cgroup示例 1、创建一个hierarchy（cgroup树） # 创建一个 hierarchy 挂载点 mkdir cgroup-test # 挂载hierarchy 挂载点 mount -t cgroup -o none,name=cgroup-test cgroup-test ./cgroup-test # 查看生成的默认文件 # ll 总用量 0 -rw-r--r-- 1 root root 0 3月 5 19:13 cgroup.clone_children --w--w--w- 1 root root 0 3月 5 19:13 cgroup.event_control -rw-r--r-- 1 root root 0 3月 5 19:13 cgroup.procs -r--r--r-- 1 root root 0 3月 5 19:13 cgroup.sane_behavior -rw-r--r-- 1 root root 0 3月 5 19:13 notify_on_release -rw-r--r-- 1 root root 0 3月 5 19:13 release_agent -rw-r--r-- 1 root root 0 3月 5 19:13 tasks 2、在根cgroup创建2个子cgroup 在cgroup目录下创建目录，子cgroup会继承父cgroup的属性。 mkdir cgroup-1 mkdir cgroup-2 # tree . ├── cgroup-1 │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── notify_on_release │ └── tasks ├── cgroup-2 │ ├── cgroup.clone_children │ ├── cgroup.event_control │ ├── cgroup.procs │ ├── notify_on_release │ └── tasks ├── cgroup.clone_children ├── cgroup.event_control ├── cgroup.procs ├── cgroup.sane_behavior ├── notify_on_release ├── release_agent └── tasks 3、在cgroup中添加和移动进程。 4、通过subsystem限制cgroup中进程的资源。 系统为每个subsystem创建了一个默认的hierarchy，具体如下： [root@runtime ~]# ll /sys/fs/cgroup/ 总用量 0 drwxr-xr-x 4 root root 0 2月 28 04:48 blkio lrwxrwxrwx 1 root root 11 2月 28 04:48 cpu -> cpu,cpuacct lrwxrwxrwx 1 root root 11 2月 28 04:48 cpuacct -> cpu,cpuacct drwxr-xr-x 5 root root 0 2月 28 04:48 cpu,cpuacct drwxr-xr-x 2 root root 0 2月 28 04:48 cpuset drwxr-xr-x 4 root root 0 2月 28 04:48 devices drwxr-xr-x 2 root root 0 2月 28 04:48 freezer drwxr-xr-x 2 root root 0 2月 28 04:48 hugetlb drwxr-xr-x 5 root root 0 2月 28 04:48 memory drwxr-xr-x 2 root root 0 2月 28 04:48 perf_event drwxr-xr-x 4 root root 0 2月 28 04:48 pids drwxr-xr-x 4 root root 0 2月 28 04:48 systemd 例如，memor的hierarchy：/sys/fs/cgroup/memory/ # ll /sys/fs/cgroup/memory/ 总用量 0 -rw-r--r-- 1 root root 0 2月 28 04:48 cgroup.clone_children --w--w--w- 1 root root 0 2月 28 04:48 cgroup.event_control -rw-r--r-- 1 root root 0 2月 28 04:48 cgroup.procs -r--r--r-- 1 root root 0 2月 28 04:48 cgroup.sane_behavior -rw-r--r-- 1 root root 0 2月 28 04:48 memory.failcnt --w------- 1 root root 0 2月 28 04:48 memory.force_empty -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.failcnt -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 2月 28 04:48 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 2月 28 04:48 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 2月 28 04:48 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.limit_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.max_usage_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.memsw.failcnt -rw-r--r-- 1 root root 0 2月 28 04:48 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 2月 28 04:48 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 2月 28 04:48 memory.numa_stat -rw-r--r-- 1 root root 0 2月 28 04:48 memory.oom_control ---------- 1 root root 0 2月 28 04:48 memory.pressure_level -rw-r--r-- 1 root root 0 2月 28 04:48 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 2月 28 04:48 memory.stat -rw-r--r-- 1 root root 0 2月 28 04:48 memory.swappiness -r--r--r-- 1 root root 0 2月 28 04:48 memory.usage_in_bytes -rw-r--r-- 1 root root 0 2月 28 04:48 memory.use_hierarchy -rw-r--r-- 1 root root 0 2月 28 04:48 notify_on_release -rw-r--r-- 1 root root 0 2月 28 04:48 release_agent drwxr-xr-x 65 root root 0 3月 9 16:11 system.slice -rw-r--r-- 1 root root 0 2月 28 04:48 tasks drwxr-xr-x 2 root root 0 2月 28 04:48 user.slice drwxr-xr-x 2 root root 0 2月 28 21:30 YunJing 在/sys/fs/cgroup/memory/中创建cgroup，限制进程内存使用。 cd /sys/fs/cgroup/memory/ && mkdir cgroup-test # 查看文件 # ll /sys/fs/cgroup/memory/cgroup-test/ 总用量 0 -rw-r--r-- 1 root root 0 3月 9 16:28 cgroup.clone_children --w--w--w- 1 root root 0 3月 9 16:28 cgroup.event_control -rw-r--r-- 1 root root 0 3月 9 16:28 cgroup.procs -rw-r--r-- 1 root root 0 3月 9 16:28 memory.failcnt --w------- 1 root root 0 3月 9 16:28 memory.force_empty -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.failcnt -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 3月 9 16:28 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 3月 9 16:28 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 3月 9 16:28 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.limit_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.max_usage_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.memsw.failcnt -rw-r--r-- 1 root root 0 3月 9 16:28 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 3月 9 16:28 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 3月 9 16:28 memory.numa_stat -rw-r--r-- 1 root root 0 3月 9 16:28 memory.oom_control ---------- 1 root root 0 3月 9 16:28 memory.pressure_level -rw-r--r-- 1 root root 0 3月 9 16:28 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 3月 9 16:28 memory.stat -rw-r--r-- 1 root root 0 3月 9 16:28 memory.swappiness -r--r--r-- 1 root root 0 3月 9 16:28 memory.usage_in_bytes -rw-r--r-- 1 root root 0 3月 9 16:28 memory.use_hierarchy -rw-r--r-- 1 root root 0 3月 9 16:28 notify_on_release -rw-r--r-- 1 root root 0 3月 9 16:28 tasks 5、限制进程资源 拉起测试进程，内存占用为200M # stress --vm-bytes 200m --vm-keep -m 1 stress: info: [31581] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd # ps auxw|grep stress root 31585 20.6 10.8 214204 204888 pts/1 R+ 16:32 0:18 stress --vm-bytes 200m --vm-keep -m 1 # 可见内存使用 204888kB 即204M # top -p 31585 PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 31585 root 20 0 214204 204888 124 R 21.3 10.9 0:14.92 stress 限制内存 3. cgroup常用命令 3.1. cgcreate $ cgcreate --help Usage: cgcreate [-h] [-f mode] [-d mode] [-s mode] [-t :] [-a :] -g : [-g ...] Create control group(s) -a : Owner of the group and all its files -d, --dperm=mode Group directory permissions -f, --fperm=mode Group file permissions -g : Control group which should be added -h, --help Display this help -s, --tperm=mode Tasks file permissions -t : Owner of the tasks file 示例： cpu # cgcreate -g cpu:cgrouptest # ll /sys/fs/cgroup/cpu/cgrouptest 总用量 0 -rw-rw-r-- 1 root root 0 8月 15 20:14 cgroup.clone_children --w--w---- 1 root root 0 8月 15 20:14 cgroup.event_control -rw-rw-r-- 1 root root 0 8月 15 20:14 cgroup.procs -r--r--r-- 1 root root 0 8月 15 20:14 cpuacct.stat -r--r--r-- 1 root root 0 8月 15 20:14 cpuacct.uptime -rw-rw-r-- 1 root root 0 8月 15 20:14 cpuacct.usage -r--r--r-- 1 root root 0 8月 15 20:14 cpuacct.usage_percpu -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.cfs_period_us -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.cfs_quota_us -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.cfs_relax_thresh_sec -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.rt_period_us -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.rt_runtime_us -rw-rw-r-- 1 root root 0 8月 15 20:14 cpu.shares -r--r--r-- 1 root root 0 8月 15 20:14 cpu.stat -rw-rw-r-- 1 root root 0 8月 15 20:14 notify_on_release -rw-rw-r-- 1 root root 0 8月 15 20:14 tasks memory # cgcreate -g memory:cgrouptest # ll /sys/fs/cgroup/memory/cgrouptest 总用量 0 -rw-rw-r-- 1 root root 0 8月 15 20:16 cgroup.clone_children --w--w---- 1 root root 0 8月 15 20:16 cgroup.event_control -rw-rw-r-- 1 root root 0 8月 15 20:16 cgroup.procs -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.failcnt --w--w---- 1 root root 0 8月 15 20:16 memory.force_empty -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.failcnt -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.limit_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.kmem.slabinfo -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.tcp.failcnt -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.tcp.limit_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.kmem.usage_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.limit_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.meminfo -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.memsw.failcnt -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.memsw.limit_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.memsw.usage_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 8月 15 20:16 memory.numa_stat -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.oom_control ---------- 1 root root 0 8月 15 20:16 memory.pressure_level -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 8月 15 20:16 memory.stat -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.swappiness -r--r--r-- 1 root root 0 8月 15 20:16 memory.usage_in_bytes -rw-rw-r-- 1 root root 0 8月 15 20:16 memory.use_hierarchy -r--r--r-- 1 root root 0 8月 15 20:16 memory.vmstat -rw-rw-r-- 1 root root 0 8月 15 20:16 notify_on_release -rw-rw-r-- 1 root root 0 8月 15 20:16 tasks 3.2. cgclassify $ cgclassify --help Usage: cgclassify [[-g] :] [--sticky | --cancel-sticky] Move running task(s) to given cgroups -h, --help Display this help -g : Control group to be used as target --cancel-sticky cgred daemon change pidlist and children tasks --sticky cgred daemon does not change pidlist and children tasks 4. cgroup的目录 /sys/fs/cgroup/ $ ll /sys/fs/cgroup/ 总用量 0 drwxr-xr-x 6 root root 0 2月 18 14:31 blkio lrwxrwxrwx 1 root root 11 2月 18 14:25 cpu -> cpu,cpuacct lrwxrwxrwx 1 root root 11 2月 18 14:25 cpuacct -> cpu,cpuacct drwxr-xr-x 6 root root 0 2月 18 14:31 cpu,cpuacct drwxr-xr-x 4 root root 0 2月 18 14:25 cpuset drwxr-xr-x 6 root root 0 2月 18 14:31 devices drwxr-xr-x 4 root root 0 2月 18 14:25 freezer drwxr-xr-x 4 root root 0 2月 18 14:25 hugetlb drwxr-xr-x 6 root root 0 2月 18 14:31 memory drwxr-xr-x 4 root root 0 2月 18 14:25 net_cls drwxr-xr-x 2 root root 0 2月 18 14:25 oom drwxr-xr-x 4 root root 0 2月 18 14:25 perf_event drwxr-xr-x 6 root root 0 2月 18 14:31 pids drwxr-xr-x 6 root root 0 2月 18 14:25 systemd 4.1. docker中cgroup目录 4.1.1. cpu /sys/fs/cgroup/cpu/docker/32a294d870965072acbf544da0c93a1692660d908bd72de43d1da48852083094 # ll /sys/fs/cgroup/cpu/docker/32a294d870965072acbf544da0c93a1692660d908bd72de43d1da48852083094 总用量 0 -rw-r--r-- 1 root root 0 7月 8 17:04 cgroup.clone_children --w--w--w- 1 root root 0 7月 8 17:04 cgroup.event_control -rw-r--r-- 1 root root 0 7月 8 17:04 cgroup.procs -r--r--r-- 1 root root 0 7月 8 17:04 cpuacct.stat -r--r--r-- 1 root root 0 7月 8 17:04 cpuacct.uptime -rw-r--r-- 1 root root 0 7月 8 17:04 cpuacct.usage -r--r--r-- 1 root root 0 7月 8 17:04 cpuacct.usage_percpu -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.cfs_period_us -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.cfs_quota_us -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.cfs_relax_thresh_sec -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.rt_period_us -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.rt_runtime_us -rw-r--r-- 1 root root 0 7月 8 17:04 cpu.shares -r--r--r-- 1 root root 0 7月 8 17:04 cpu.stat -rw-r--r-- 1 root root 0 7月 8 17:04 notify_on_release -rw-r--r-- 1 root root 0 7月 8 17:04 tasks 4.1.2. memory # ll /sys/fs/cgroup/memory/docker/32a294d870965072acbf544da0c93a1692660d908bd72de43d1da48852083094 总用量 0 -rw-r--r-- 1 root root 0 7月 8 17:04 cgroup.clone_children --w--w--w- 1 root root 0 7月 8 17:04 cgroup.event_control -rw-r--r-- 1 root root 0 7月 8 17:04 cgroup.procs -rw-r--r-- 1 root root 0 7月 8 17:04 memory.failcnt --w------- 1 root root 0 7月 8 17:04 memory.force_empty -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.failcnt -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.limit_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.max_usage_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.meminfo -rw-r--r-- 1 root root 0 7月 8 17:04 memory.memsw.failcnt -rw-r--r-- 1 root root 0 7月 8 17:04 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 7月 8 17:04 memory.numa_stat -rw-r--r-- 1 root root 0 7月 8 17:04 memory.oom_control ---------- 1 root root 0 7月 8 17:04 memory.pressure_level -rw-r--r-- 1 root root 0 7月 8 17:04 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 7月 8 17:04 memory.stat -rw-r--r-- 1 root root 0 7月 8 17:04 memory.swappiness -r--r--r-- 1 root root 0 7月 8 17:04 memory.usage_in_bytes -rw-r--r-- 1 root root 0 7月 8 17:04 memory.use_hierarchy -r--r--r-- 1 root root 0 7月 8 17:04 memory.vmstat -rw-r--r-- 1 root root 0 7月 8 17:04 notify_on_release -rw-r--r-- 1 root root 0 7月 8 17:04 tasks 4.2. pod中cgroup目录 4.2.1. cpu #ll /sys/fs/cgroup/cpu/kubepods/burstable/pode90435b5-4673-4bc2-9892-1f4825af5039/f62fb0f76b5b48cf903680296a1ba2abc314fdbf51e023886d06f8470d5ca90d 总用量 0 -rw-r--r-- 1 root root 0 8月 14 15:33 cgroup.clone_children --w--w--w- 1 root root 0 8月 14 15:33 cgroup.event_control -rw-r--r-- 1 root root 0 8月 14 15:33 cgroup.procs -r--r--r-- 1 root root 0 8月 14 15:33 cpuacct.stat -r--r--r-- 1 root root 0 8月 14 15:33 cpuacct.uptime -rw-r--r-- 1 root root 0 8月 14 15:33 cpuacct.usage -r--r--r-- 1 root root 0 8月 14 15:33 cpuacct.usage_percpu -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.cfs_period_us # -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.cfs_quota_us # -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.cfs_relax_thresh_sec -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.rt_period_us -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.rt_runtime_us -rw-r--r-- 1 root root 0 8月 14 15:33 cpu.shares # -r--r--r-- 1 root root 0 8月 14 15:33 cpu.stat -rw-r--r-- 1 root root 0 8月 14 15:33 notify_on_release -rw-r--r-- 1 root root 0 8月 14 15:33 tasks 4.2.2. memory #ll /sys/fs/cgroup/memory/kubepods/burstable/pode90435b5-4673-4bc2-9892-1f4825af5039/f62fb0f76b5b48cf903680296a1ba2abc314fdbf51e023886d06f8470d5ca90d 总用量 0 -rw-r--r-- 1 root root 0 8月 14 15:33 cgroup.clone_children --w--w--w- 1 root root 0 8月 14 15:33 cgroup.event_control -rw-r--r-- 1 root root 0 8月 14 15:33 cgroup.procs -rw-r--r-- 1 root root 0 8月 14 15:33 memory.failcnt --w------- 1 root root 0 8月 14 15:33 memory.force_empty -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.failcnt -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.limit_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.meminfo -rw-r--r-- 1 root root 0 8月 14 15:33 memory.memsw.failcnt -rw-r--r-- 1 root root 0 8月 14 15:33 memory.memsw.limit_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.memsw.max_usage_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.memsw.usage_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 8月 14 15:33 memory.numa_stat -rw-r--r-- 1 root root 0 8月 14 15:33 memory.oom_control ---------- 1 root root 0 8月 14 15:33 memory.pressure_level -rw-r--r-- 1 root root 0 8月 14 15:33 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 8月 14 15:33 memory.stat -rw-r--r-- 1 root root 0 8月 14 15:33 memory.swappiness -r--r--r-- 1 root root 0 8月 14 15:33 memory.usage_in_bytes -rw-r--r-- 1 root root 0 8月 14 15:33 memory.use_hierarchy -r--r--r-- 1 root root 0 8月 14 15:33 memory.vmstat -rw-r--r-- 1 root root 0 8月 14 15:33 notify_on_release -rw-r--r-- 1 root root 0 8月 14 15:33 tasks 参考： https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-09 17:19:40 "},"code-analysis/code-analysis-of-docker-client.html":{"url":"code-analysis/code-analysis-of-docker-client.html","title":"Docker Client","keywords":"","body":"1. 创建Docker Client ​ Docker是一个client/server的架构，通过二进制文件docker创建Docker客户端将请求类型与参数发送给Docker Server，Docker Server具体执行命令调用。 Docker Client运行流程图如下： 说明：本文分析的代码为Docker 1.2.0版本。 1.1. Docker命令flag参数解析 Docker Server与Docker Client由可执行文件docker命令创建并启动。 Docker Server的启动：docker -d或docker --daemon=true Docker Client的启动：docker --daemon=false ps等 docker参数分为两类： 命令行参数（flag参数）:--daemon=true,-d 实际请求参数:ps ,images, pull, push等 /docker/docker.go func main() { if reexec.Init() { return } flag.Parse() // FIXME: validate daemon flags here ...... } reexec.Init()作用：协调execdriver与容器创建时dockerinit的关系。如果返回值为真则直接退出运行，否则继续执行。判断reexec.Init()之后，调用flag.Parse()解析命令行中的flag参数。 /docker/flag.go var ( flVersion = flag.Bool([]string{\"v\", \"-version\"}, false, \"Print version information and quit\") flDaemon = flag.Bool([]string{\"d\", \"-daemon\"}, false, \"Enable daemon mode\") flDebug = flag.Bool([]string{\"D\", \"-debug\"}, false, \"Enable debug mode\") flSocketGroup = flag.String([]string{\"G\", \"-group\"}, \"docker\", \"Group to assign the unix socket specified by -H when running in daemon mode/nuse '' (the empty string) to disable setting of a group\") flEnableCors = flag.Bool([]string{\"#api-enable-cors\", \"-api-enable-cors\"}, false, \"Enable CORS headers in the remote API\") flTls = flag.Bool([]string{\"-tls\"}, false, \"Use TLS; implied by tls-verify flags\") flTlsVerify = flag.Bool([]string{\"-tlsverify\"}, false, \"Use TLS and verify the remote (daemon: verify client, client: verify daemon)\") // these are initialized in init() below since their default values depend on dockerCertPath which isn't fully initialized until init() runs flCa *string flCert *string flKey *string flHosts []string ) func init() { flCa = flag.String([]string{\"-tlscacert\"}, filepath.Join(dockerCertPath, defaultCaFile), \"Trust only remotes providing a certificate signed by the CA given here\") flCert = flag.String([]string{\"-tlscert\"}, filepath.Join(dockerCertPath, defaultCertFile), \"Path to TLS certificate file\") flKey = flag.String([]string{\"-tlskey\"}, filepath.Join(dockerCertPath, defaultKeyFile), \"Path to TLS key file\") opts.HostListVar(&flHosts, []string{\"H\", \"-host\"}, \"The socket(s) to bind to in daemon mode/nspecified using one or more tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd.\") } flag.go定义了flag参数，并执行了init的初始化。 Go中的init函数 用于程序执行前包的初始化工作，比如初始化变量 每个包或源文件可以包含多个init函数 init函数不能被调用，而是在mian函数调用前自动被调用 不同init函数的执行顺序，按照包导入的顺序执行 当解析到第一个非flag参数时，flag解析工作就结束。例如docker --daemon=flase --version=false ps 完成flag的解析，--daemon=false 遇到第一个非flag参数ps，则将ps及其后的参数存入flag.Args()，以便执行之后的具体请求。 1.2. 处理flag参数并收集Docker Client的配置信息 处理的flag参数有flVersion,flDebug,flDaemon,flTlsVerify以及flTls。 /docker/docker.go func main() { ...... if len(flHosts) == 0 { defaultHost := os.Getenv(\"DOCKER_HOST\") if defaultHost == \"\" || *flDaemon { // If we do not have a host, default to unix socket defaultHost = fmt.Sprintf(\"unix://%s\", api.DEFAULTUNIXSOCKET) } if _, err := api.ValidateHost(defaultHost); err != nil { log.Fatal(err) } flHosts = append(flHosts, defaultHost) } ...... } flHosts的作用是为Docker Client提供所要连接的host对象，也就是为Docker Server提供所要监听的对象。 当flHosts为空，默认取环境变量DOCKER_HOST，若仍为空或flDaemon为真，则设置为unix socket，值为unix:///var/run/docker.sock。取自/api/common.go中的常量DEFAULTUNIXSOCKET。 /docker/docker.go func main() { ... if *flDaemon { mainDaemon() return } ... } 若flDaemon为真，表示启动Docker Daemon，调用/docker/daemon.go中的func mainDaemon()。 /docker/docker.go if len(flHosts) > 1 { log.Fatal(\"Please specify only one -H\") } protoAddrParts := strings.SplitN(flHosts[0], \"://\", 2) protoAddrParts的作用是解析出Docker Client 与Docker Server建立通信的协议与地址，通过strings.SplitN函数分割存储。flHosts[0]的值可以是tcp://0.0.0.0.2375或者unix:///var/run/docker.sock等。 /docker/docker.go var ( cli *client.DockerCli tlsConfig tls.Config ) tlsConfig.InsecureSkipVerify = true tlsConfig对象的创建是为了保障cli在传输数据的时候遵循安全传输层协议（TLS）。flTlsVerity参数为真，则说明Docker Client 需Docker Server一起验证连接的安全性，如果flTls和flTlsVerity两个参数中有一个为真，则说明需要加载并发送客户端的证书。 /docker/flags.go flTls = flag.Bool([]string{\"-tls\"}, false, \"Use TLS; implied by tls-verify flags\") flTlsVerify = flag.Bool([]string{\"-tlsverify\"}, false, \"Use TLS and verify the remote (daemon: verify client, client: verify daemon)\") 1.3. 如何创建Docker Client /docker/docker.go if *flTls || *flTlsVerify { cli = client.NewDockerCli(os.Stdin, os.Stdout, os.Stderr, protoAddrParts[0], protoAddrParts[1], &tlsConfig) } else { cli = client.NewDockerCli(os.Stdin, os.Stdout, os.Stderr, protoAddrParts[0], protoAddrParts[1], nil) } 在已有配置参数的情况下，通过/api/client/cli.go中的NewDockerCli方法创建Docker Client实例cli。 /api/client/cli.go type DockerCli struct { proto string addr string configFile *registry.ConfigFile in io.ReadCloser out io.Writer err io.Writer isTerminal bool terminalFd uintptr tlsConfig *tls.Config scheme string } func NewDockerCli(in io.ReadCloser, out, err io.Writer, proto, addr string, tlsConfig *tls.Config) *DockerCli { var ( isTerminal = false terminalFd uintptr scheme = \"http\" ) if tlsConfig != nil { scheme = \"https\" } if in != nil { if file, ok := out.(*os.File); ok { terminalFd = file.Fd() isTerminal = term.IsTerminal(terminalFd) } } if err == nil { err = out } return &DockerCli{ proto: proto, addr: addr, in: in, out: out, err: err, isTerminal: isTerminal, terminalFd: terminalFd, tlsConfig: tlsConfig, scheme: scheme, } } 2. Docke命令执行 2.1. Docker Client解析请求命令 创建Docker Client，docker命令中的请求参数（例如ps，经flag解析后放入flag.Args()），分析请求参数及请求的类型，转义为Docker Server可识别的请求后发给Docker Server。 /docker/docker.go if err := cli.Cmd(flag.Args()...); err != nil { if sterr, ok := err.(*utils.StatusError); ok { if sterr.Status != \"\" { log.Println(sterr.Status) } os.Exit(sterr.StatusCode) } log.Fatal(err) } 解析flag.Args()的具体请求参数，执行cli.Cmd函数。代码在/api/client/cli.go /api/client/cli.go // Cmd executes the specified command func (cli *DockerCli) Cmd(args ...string) error { if len(args) > 0 { method, exists := cli.getMethod(args[0]) if !exists { fmt.Println(\"Error: Command not found:\", args[0]) return cli.CmdHelp(args[1:]...) } return method(args[1:]...) } return cli.CmdHelp(args...) } method, exists := cli.getMethod(args[0])获取请求参数，例如docker pull ImageName，args[0]等于pull。 func (cli *DockerCli) getMethod(name string) (func(...string) error, bool) { if len(name) == 0 { return nil, false } methodName := \"Cmd\" + strings.ToUpper(name[:1]) + strings.ToLower(name[1:]) method := reflect.ValueOf(cli).MethodByName(methodName) if !method.IsValid() { return nil, false } return method.Interface().(func(...string) error), true } 在getMethod中，返回method值为“CmdPull”。最后执行method(args[1:]...)，即CmdPull(args[1:]...)。 2.2. Docker Client执行请求命令 docker pull ImageName中，即执行CmdPull(args[1:]...)，args[1:]即为ImageName。命令代码在/api/client/command.go。 /api/client/commands.go func (cli *DockerCli) CmdPull(args ...string) error { cmd := cli.Subcmd(\"pull\", \"NAME[:TAG]\", \"Pull an image or a repository from the registry\") tag := cmd.String([]string{\"#t\", \"#-tag\"}, \"\", \"Download tagged image in a repository\") if err := cmd.Parse(args); err != nil { return nil } ... } 将args参数进行第二次flag参数解析，解析过程中先提取是否有符合tag这个flag的参数，若有赋值给tag参数，其余存入cmd.NArg()，若没有则所有的参数存入cmd.NArg()中。 /api/client/commands.go var ( v = url.Values{} remote = cmd.Arg(0) ) v.Set(\"fromImage\", remote) if *tag == \"\" { v.Set(\"tag\", *tag) } remote, _ = parsers.ParseRepositoryTag(remote) // Resolve the Repository name from fqn to hostname + name hostname, _, err := registry.ResolveRepositoryName(remote) if err != nil { return err } 通过remote变量先得到镜像的repository名称，并赋值给remote自身，随后解析改变后的remote，得出镜像所在的host地址，即Docker Registry的地址。若没有指定默认为Docker Hub地址https://index.docker.io/v1/。 /api/client/commands.go cli.LoadConfigFile() // Resolve the Auth config relevant for this server authConfig := cli.configFile.ResolveAuthConfig(hostname) 通过cli对象获取与Docker Server的认证配置信息。 /api/client/commands.go pull := func(authConfig registry.AuthConfig) error { buf, err := json.Marshal(authConfig) if err != nil { return err } registryAuthHeader := []string{ base64.URLEncoding.EncodeToString(buf), } return cli.stream(\"POST\", \"/images/create?\"+v.Encode(), nil, cli.out, map[string][]string{ \"X-Registry-Auth\": registryAuthHeader, }) } 定义pull函数：cli.stream(\"POST\", \"/images/create?\"+v.Encode(),...)像Docker Server发送POST请求，请求url为“\"/images/create?\"+v.Encode()”，请求的认证信息为：map[string][]string{\"X-Registry-Auth\": registryAuthHeader,} /api/client/commands.go if err := pull(authConfig); err != nil { if strings.Contains(err.Error(), \"Status 401\") { fmt.Fprintln(cli.out, \"/nPlease login prior to pull:\") if err := cli.CmdLogin(hostname); err != nil { return err } authConfig := cli.configFile.ResolveAuthConfig(hostname) return pull(authConfig) } return err } return nil 调用pull函数，实现下载请求发送。后续有Docker Server接收到请求后具体实现。 参考： 《Docker源码分析》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"code-analysis/code-analysis-of-docker-daemon.html":{"url":"code-analysis/code-analysis-of-docker-daemon.html","title":"Docker Daemon","keywords":"","body":"1. Docker Daemon架构示意图 Docker Daemon是Docker架构中运行在后台的守护进程，大致可以分为Docker Server、Engine和Job三部分。 Docker Daemon可以认为是通过Docker Server模块接受Docker Client的请求，并在Engine中处理请求，然后根据请求类型，创建出指定的Job并运行。 运行过程的作用有以下几种可能： 向Docker Registry获取镜像， 通过graphdriver执行容器镜像的本地化操作， 通过networkdriver执行容器网络环境的配置， 通过execdriver执行容器内部运行的执行工作等。 说明：本文分析的代码为Docker 1.2.0版本。 2. Docker Daemon启动流程图 启动Docker Daemon时，一般可以使用以下命令：docker --daemon=true; docker –d; docker –d=true等。接着由docker的main()函数来解析以上命令的相应flag参数，并最终完成Docker Daemon的启动。 /docker/docker.go func main() { ... if *flDaemon { mainDaemon() return } ... } 3. mainDaemon的具体实现 宏观来讲，mainDaemon()完成创建一个daemon进程，并使其正常运行。 从功能的角度来说，mainDaemon()实现了两部分内容： 第一，创建Docker运行环境； 第二，服务于Docker Client，接收并处理相应请求。 3.1. 配置初始化 /docker/daemon.go var ( daemonCfg = &daemon.Config{} ) func init() { daemonCfg.InstallFlags() } 在mainDaemon()运行之前，关于Docker Daemon所需要的config配置信息均已经初始化完毕。 声明一个为daemon包中Config类型的变量，名为daemonCfg。而Config对象，定义了Docker Daemon所需的配置信息。在Docker Daemon在启动时，daemonCfg变量被传递至Docker Daemon并被使用。 /daemon/config.go type Config struct { Pidfile string //Docker Daemon所属进程的PID文件 Root string //Docker运行时所使用的root路径 AutoRestart bool //已被启用，转而支持docker run时的重启 Dns []string //Docker使用的DNS Server地址 DnsSearch []string //Docker使用的指定的DNS查找域名 Mirrors []string //指定的优先Docker Registry镜像 EnableIptables bool //启用Docker的iptables功能 EnableIpForward bool //启用net.ipv4.ip_forward功能 EnableIpMasq bool //启用IP伪装技术 DefaultIp net.IP //绑定容器端口时使用的默认IP BridgeIface string //添加容器网络至已有的网桥 BridgeIP string //创建网桥的IP地址 FixedCIDR string //指定IP的IPv4子网，必须被网桥子网包含 InterContainerCommunication bool //是否允许相同host上容器间的通信 GraphDriver string //Docker运行时使用的特定存储驱动 GraphOptions []string //可设置的存储驱动选项 ExecDriver string // Docker运行时使用的特定exec驱动 Mtu int //设置容器网络的MTU DisableNetwork bool //有定义，之后未初始化 EnableSelinuxSupport bool //启用SELinux功能的支持 Context map[string][]string //有定义，之后未初始化 } init()函数实现了daemonCfg变量中各属性的赋值，具体的实现为：daemonCfg.InstallFlags() /daemon/config.go // InstallFlags adds command-line options to the top-level flag parser for // the current process. // Subsequent calls to `flag.Parse` will populate config with values parsed // from the command-line. func (config *Config) InstallFlags() { flag.StringVar(&config.Pidfile, []string{\"p\", \"-pidfile\"}, \"/var/run/docker.pid\", \"Path to use for daemon PID file\") flag.StringVar(&config.Root, []string{\"g\", \"-graph\"}, \"/var/lib/docker\", \"Path to use as the root of the Docker runtime\") flag.BoolVar(&config.AutoRestart, []string{\"#r\", \"#-restart\"}, true, \"--restart on the daemon has been deprecated infavor of --restart policies on docker run\") flag.BoolVar(&config.EnableIptables, []string{\"#iptables\", \"-iptables\"}, true, \"Enable Docker's addition of iptables rules\") flag.BoolVar(&config.EnableIpForward, []string{\"#ip-forward\", \"-ip-forward\"}, true, \"Enable net.ipv4.ip_forward\") flag.StringVar(&config.BridgeIP, []string{\"#bip\", \"-bip\"}, \"\", \"Use this CIDR notation address for the network bridge's IP, not compatible with -b\") flag.StringVar(&config.BridgeIface, []string{\"b\", \"-bridge\"}, \"\", \"Attach containers to a pre-existing network bridge/nuse 'none' to disable container networking\") flag.BoolVar(&config.InterContainerCommunication, []string{\"#icc\", \"-icc\"}, true, \"Enable inter-container communication\") flag.StringVar(&config.GraphDriver, []string{\"s\", \"-storage-driver\"}, \"\", \"Force the Docker runtime to use a specific storage driver\") flag.StringVar(&config.ExecDriver, []string{\"e\", \"-exec-driver\"}, \"native\", \"Force the Docker runtime to use a specific exec driver\") flag.BoolVar(&config.EnableSelinuxSupport, []string{\"-selinux-enabled\"}, false, \"Enable selinux support. SELinux does not presently support the BTRFS storage driver\") flag.IntVar(&config.Mtu, []string{\"#mtu\", \"-mtu\"}, 0, \"Set the containers network MTU/nif no value is provided: default to the default route MTU or 1500 if no default route is available\") opts.IPVar(&config.DefaultIp, []string{\"#ip\", \"-ip\"}, \"0.0.0.0\", \"Default IP address to use when binding container ports\") opts.ListVar(&config.GraphOptions, []string{\"-storage-opt\"}, \"Set storage driver options\") // FIXME: why the inconsistency between \"hosts\" and \"sockets\"? opts.IPListVar(&config.Dns, []string{\"#dns\", \"-dns\"}, \"Force Docker to use specific DNS servers\") opts.DnsSearchListVar(&config.DnsSearch, []string{\"-dns-search\"}, \"Force Docker to use specific DNS search domains\") } 在InstallFlags()函数的实现过程中，主要是定义某种类型的flag参数，并将该参数的值绑定在config变量的指定属性上，如： flag.StringVar(&config.Pidfile, []string{\"p\", \"-pidfile\"}, \" /var/run/docker.pid\", \"Path to use for daemon PID file\") 以上语句的含义为： 定义一个为String类型的flag参数； 该flag的名称为”p”或者”-pidfile”; 该flag的值为” /var/run/docker.pid”,并将该值绑定在变量config.Pidfile上； 该flag的描述信息为\"Path to use for daemon PID file\"。 3.2. flag参数检查 /docker/daemon.go if flag.NArg() != 0 { flag.Usage() return } 参数个数不为0，则说明在启动Docker Daemon的时候，传入了多余的参数，此时会输出错误提示，并退出运行程序。 若为0，则说明Docker Daemon的启动命令无误，正常运行。 3.3. 创建engine对象 /docker/daemon.go eng := engine.New() Engine是Docker架构中的运行引擎，同时也是Docker运行的核心模块。Engine扮演着Docker container存储仓库的角色，并且通过job的形式来管理这些容器。 /engine/engine.go type Engine struct { handlers map[string]Handler catchall Handler hack Hack // data for temporary hackery (see hack.go) id string Stdout io.Writer Stderr io.Writer Stdin io.Reader Logging bool tasks sync.WaitGroup l sync.RWMutex // lock for shutdown shutdown bool onShutdown []func() // shutdown handlers } Engine结构体中最为重要的即为handlers属性。该handlers属性为map类型，key为string类型，value为Handler类型。Handler为一个定义的函数。该函数传入的参数为Job指针，返回为Status状态。 /engine/engine.go type Handler func(*Job) Status New()函数的实现: /engine/engine.go // New initializes a new engine. func New() *Engine { eng := &Engine{ handlers: make(map[string]Handler), id: utils.RandomString(), Stdout: os.Stdout, Stderr: os.Stderr, Stdin: os.Stdin, Logging: true, } eng.Register(\"commands\", func(job *Job) Status { for _, name := range eng.commands() { job.Printf(\"%s/n\", name) } return StatusOK }) // Copy existing global handlers for k, v := range globalHandlers { eng.handlers[k] = v } return eng } 创建一个Engine结构体实例eng 向eng对象注册名为commands的Handler，其中Handler为临时定义的函数func(job *Job) Status{ } , 该函数的作用是通过job来打印所有已经注册完毕的command名称，最终返回状态StatusOK。 将已定义的变量globalHandlers中的所有的Handler，都复制到eng对象的handlers属性中。最后成功返回eng对象。 3.4. 设置engine的信号捕获 /daemon/daemon.go signal.Trap(eng.Shutdown) 在Docker Daemon的运行中，设置Trap特定信号的处理方法，特定信号有SIGINT，SIGTERM以及SIGQUIT；当程序捕获到SIGINT或者SIGTERM信号时，执行相应的善后操作，最后保证Docker Daemon程序退出。 /pkg/signal/trap.go //Trap sets up a simplified signal \"trap\", appropriate for common // behavior expected from a vanilla unix command-line tool in general // (and the Docker engine in particular). // // * If SIGINT or SIGTERM are received, `cleanup` is called, then the process is terminated. // * If SIGINT or SIGTERM are repeated 3 times before cleanup is complete, then cleanup is // skipped and the process terminated directly. // * If \"DEBUG\" is set in the environment, SIGQUIT causes an exit without cleanup. // func Trap(cleanup func()) { c := make(chan os.Signal, 1) signals := []os.Signal{os.Interrupt, syscall.SIGTERM} if os.Getenv(\"DEBUG\") == \"\" { signals = append(signals, syscall.SIGQUIT) } gosignal.Notify(c, signals...) go func() { interruptCount := uint32(0) for sig := range c { go func(sig os.Signal) { log.Printf(\"Received signal '%v', starting shutdown of docker.../n\", sig) switch sig { case os.Interrupt, syscall.SIGTERM: // If the user really wants to interrupt, let him do so. if atomic.LoadUint32(&interruptCount) 创建并设置一个channel，用于发送信号通知； 定义signals数组变量，初始值为os.SIGINT, os.SIGTERM;若环境变量DEBUG为空的话，则添加os.SIGQUIT至signals数组； 通过gosignal.Notify(c, signals...)中Notify函数来实现将接收到的signal信号传递给c。需要注意的是只有signals中被罗列出的信号才会被传递给c，其余信号会被直接忽略； 创建一个goroutine来处理具体的signal信号，当信号类型为os.Interrupt或者syscall.SIGTERM时，执行传入Trap函数的具体执行方法，形参为cleanup(),实参为eng.Shutdown。 Shutdown()函数的定义位于./docker/engine/engine.go，主要做的工作是为Docker Daemon的关闭做一些善后工作。 /engine/engine.go // Shutdown permanently shuts down eng as follows: // - It refuses all new jobs, permanently. // - It waits for all active jobs to complete (with no timeout) // - It calls all shutdown handlers concurrently (if any) // - It returns when all handlers complete, or after 15 seconds, // whichever happens first. func (eng *Engine) Shutdown() { eng.l.Lock() if eng.shutdown { eng.l.Unlock() return } eng.shutdown = true eng.l.Unlock() // We don't need to protect the rest with a lock, to allow // for other calls to immediately fail with \"shutdown\" instead // of hanging for 15 seconds. // This requires all concurrent calls to check for shutdown, otherwise // it might cause a race. // Wait for all jobs to complete. // Timeout after 5 seconds. tasksDone := make(chan struct{}) go func() { eng.tasks.Wait() close(tasksDone) }() select { case Docker Daemon不再接收任何新的Job； Docker Daemon等待所有存活的Job执行完毕； Docker Daemon调用所有shutdown的处理方法； 当所有的handler执行完毕，或者15秒之后，Shutdown()函数返回。 由于在signal.Trap( eng.Shutdown )函数的具体实现中执行eng.Shutdown，在执行完eng.Shutdown之后，随即执行os.Exit(0)，完成当前程序的立即退出。 3.5. 加载builtins /docker/daemon.go if err := builtins.Register(eng); err != nil { log.Fatal(err) } 为engine注册多个Handler，以便后续在执行相应任务时，运行指定的Handler。 这些Handler包括： 网络初始化、 web API服务、 事件查询、 版本查看、 Docker Registry验证与搜索。 /builtins/builtins.go func Register(eng *engine.Engine) error { if err := daemon(eng); err != nil { return err } if err := remote(eng); err != nil { return err } if err := events.New().Install(eng); err != nil { return err } if err := eng.Register(\"version\", dockerVersion); err != nil { return err } return registry.NewService().Install(eng) } 3.5.1. 注册初始化网络驱动的Handler daemon(eng)的实现过程，主要为eng对象注册了一个key为”init_networkdriver”的Handler，该Handler的值为bridge.InitDriver函数，代码如下： /builtins/builtins.go func daemon(eng *engine.Engine) error { return eng.Register(\"init_networkdriver\", bridge.InitDriver) } 需要注意的是，向eng对象注册Handler，并不代表Handler的值函数会被直接运行，如bridge.InitDriver，并不会直接运行，而是将bridge.InitDriver的函数入口，写入eng的handlers属性中。 /daemon/networkdriver/bridge/driver.go func InitDriver(job *engine.Job) engine.Status { var ( network *net.IPNet enableIPTables = job.GetenvBool(\"EnableIptables\") icc = job.GetenvBool(\"InterContainerCommunication\") ipForward = job.GetenvBool(\"EnableIpForward\") bridgeIP = job.Getenv(\"BridgeIP\") ) if defaultIP := job.Getenv(\"DefaultBindingIP\"); defaultIP != \"\" { defaultBindingIP = net.ParseIP(defaultIP) } bridgeIface = job.Getenv(\"BridgeIface\") usingDefaultBridge := false if bridgeIface == \"\" { usingDefaultBridge = true bridgeIface = DefaultNetworkBridge } addr, err := networkdriver.GetIfaceAddr(bridgeIface) if err != nil { // If we're not using the default bridge, fail without trying to create it if !usingDefaultBridge { job.Logf(\"bridge not found: %s\", bridgeIface) return job.Error(err) } // If the iface is not found, try to create it job.Logf(\"creating new bridge for %s\", bridgeIface) if err := createBridge(bridgeIP); err != nil { return job.Error(err) } job.Logf(\"getting iface addr\") addr, err = networkdriver.GetIfaceAddr(bridgeIface) if err != nil { return job.Error(err) } network = addr.(*net.IPNet) } else { network = addr.(*net.IPNet) // validate that the bridge ip matches the ip specified by BridgeIP if bridgeIP != \"\" { bip, _, err := net.ParseCIDR(bridgeIP) if err != nil { return job.Error(err) } if !network.IP.Equal(bip) { return job.Errorf(\"bridge ip (%s) does not match existing bridge configuration %s\", network.IP, bip) } } } // Configure iptables for link support if enableIPTables { if err := setupIPTables(addr, icc); err != nil { return job.Error(err) } } if ipForward { // Enable IPv4 forwarding if err := ioutil.WriteFile(\"/proc/sys/net/ipv4/ip_forward\", []byte{'1', '/n'}, 0644); err != nil { job.Logf(\"WARNING: unable to enable IPv4 forwarding: %s/n\", err) } } // We can always try removing the iptables if err := iptables.RemoveExistingChain(\"DOCKER\"); err != nil { return job.Error(err) } if enableIPTables { chain, err := iptables.NewChain(\"DOCKER\", bridgeIface) if err != nil { return job.Error(err) } portmapper.SetIptablesChain(chain) } bridgeNetwork = network // https://github.com/docker/docker/issues/2768 job.Eng.Hack_SetGlobalVar(\"httpapi.bridgeIP\", bridgeNetwork.IP) for name, f := range map[string]engine.Handler{ \"allocate_interface\": Allocate, \"release_interface\": Release, \"allocate_port\": AllocatePort, \"link\": LinkContainers, } { if err := job.Eng.Register(name, f); err != nil { return job.Error(err) } } return engine.StatusOK } Bridge.InitDriver的作用： 获取为Docker服务的网络设备的地址； 创建指定IP地址的网桥； 配置网络iptables规则； 另外还为eng对象注册了多个Handler,如 ”allocate_interface”， ”release_interface”， ”allocate_port”，”link”。 3.5.2. 注册API服务的Handler remote(eng)的实现过程，主要为eng对象注册了两个Handler，分别为”serveapi”与”acceptconnections”。代码实现如下： /builtins/builtins.go func remote(eng *engine.Engine) error { if err := eng.Register(\"serveapi\", apiserver.ServeApi); err != nil { return err } return eng.Register(\"acceptconnections\", apiserver.AcceptConnections) } 注册的两个Handler名称分别为”serveapi”与”acceptconnections” ServeApi执行时，通过循环多种协议，创建出goroutine来配置指定的http.Server，最终为不同的协议请求服务； AcceptConnections的实现主要是为了通知init守护进程，Docker Daemon已经启动完毕，可以让Docker Daemon进程接受请求。(守护进程) 3.5.3. 注册events事件的Handler events.New().Install(eng)的实现过程，为Docker注册了多个event事件，功能是给Docker用户提供API，使得用户可以通过这些API查看Docker内部的events信息，log信息以及subscribers_count信息。 /events/events.go type Events struct { mu sync.RWMutex events []*utils.JSONMessage subscribers []listener } func New() *Events { return &Events{ events: make([]*utils.JSONMessage, 0, eventsLimit), } } // Install installs events public api in docker engine func (e *Events) Install(eng *engine.Engine) error { // Here you should describe public interface jobs := map[string]engine.Handler{ \"events\": e.Get, \"log\": e.Log, \"subscribers_count\": e.SubscribersCount, } for name, job := range jobs { if err := eng.Register(name, job); err != nil { return err } } return nil } 3.5.4. 注册版本的Handler eng.Register(“version”,dockerVersion)的实现过程，向eng对象注册key为”version”，value为”dockerVersion”执行方法的Handler，dockerVersion的执行过程中，会向名为version的job的标准输出中写入Docker的版本，Docker API的版本，git版本，Go语言运行时版本以及操作系统等版本信息。 /builtins/builtins.go // builtins jobs independent of any subsystem func dockerVersion(job *engine.Job) engine.Status { v := &engine.Env{} v.SetJson(\"Version\", dockerversion.VERSION) v.SetJson(\"ApiVersion\", api.APIVERSION) v.Set(\"GitCommit\", dockerversion.GITCOMMIT) v.Set(\"GoVersion\", runtime.Version()) v.Set(\"Os\", runtime.GOOS) v.Set(\"Arch\", runtime.GOARCH) if kernelVersion, err := kernel.GetKernelVersion(); err == nil { v.Set(\"KernelVersion\", kernelVersion.String()) } if _, err := v.WriteTo(job.Stdout); err != nil { return job.Error(err) } return engine.StatusOK } 3.5.5. 注册registry的Handler registry.NewService().Install(eng)的实现过程位于./docker/registry/service.go，在eng对象对外暴露的API信息中添加docker registry的信息。当registry.NewService()成功被Install安装完毕的话，则有两个调用能够被eng使用：”auth”，向公有registry进行认证；”search”，在公有registry上搜索指定的镜像。 /registry/service.go // NewService returns a new instance of Service ready to be // installed no an engine. func NewService() *Service { return &Service{} } // Install installs registry capabilities to eng. func (s *Service) Install(eng *engine.Engine) error { eng.Register(\"auth\", s.Auth) eng.Register(\"search\", s.Search) return nil } 3.6. 使用goroutine加载daemon对象 执行完builtins的加载，回到mainDaemon()的执行，通过一个goroutine来加载daemon对象并开始运行。这一环节的执行，主要包含三个步骤： 通过init函数中初始化的daemonCfg与eng对象来创建一个daemon对象d；(守护进程) 通过daemon对象的Install函数，向eng对象中注册众多的Handler； 在Docker Daemon启动完毕之后，运行名为”acceptconnections”的job，主要工作为向init守护进程发送”READY=1”信号，以便开始正常接受请求。 /docker/daemon.go // load the daemon in the background so we can immediately start // the http api so that connections don't fail while the daemon // is booting go func() { d, err := daemon.NewDaemon(daemonCfg, eng) if err != nil { log.Fatal(err) } if err := d.Install(eng); err != nil { log.Fatal(err) } // after the daemon is done setting up we can tell the api to start // accepting connections if err := eng.Job(\"acceptconnections\").Run(); err != nil { log.Fatal(err) } }() 3.6.1. 创建daemon对象 /docker/daemon.go d, err := daemon.NewDaemon(daemonCfg, eng) if err != nil { log.Fatal(err) } daemon.NewDaemon(daemonCfg, eng)是创建daemon对象d的核心部分。主要作用为初始化Docker Daemon的基本环境，如处理config参数，验证系统支持度，配置Docker工作目录，设置与加载多种driver，创建graph环境等，验证DNS配置等。具体参考NewDaemon 。 3.6.2. 通过daemon对象为engine注册Handler 当创建完daemon对象，goroutine执行d.Install(eng) /daemon/daemon.go type Daemon struct { repository string sysInitPath string containers *contStore graph *graph.Graph repositories *graph.TagStore idIndex *truncindex.TruncIndex sysInfo *sysinfo.SysInfo volumes *graph.Graph eng *engine.Engine config *Config containerGraph *graphdb.Database driver graphdriver.Driver execDriver execdriver.Driver } // Install installs daemon capabilities to eng. func (daemon *Daemon) Install(eng *engine.Engine) error { // FIXME: rename \"delete\" to \"rm\" for consistency with the CLI command // FIXME: rename ContainerDestroy to ContainerRm for consistency with the CLI command // FIXME: remove ImageDelete's dependency on Daemon, then move to graph/ for name, method := range map[string]engine.Handler{ \"attach\": daemon.ContainerAttach, \"build\": daemon.CmdBuild, \"commit\": daemon.ContainerCommit, \"container_changes\": daemon.ContainerChanges, \"container_copy\": daemon.ContainerCopy, \"container_inspect\": daemon.ContainerInspect, \"containers\": daemon.Containers, \"create\": daemon.ContainerCreate, \"delete\": daemon.ContainerDestroy, \"export\": daemon.ContainerExport, \"info\": daemon.CmdInfo, \"kill\": daemon.ContainerKill, \"logs\": daemon.ContainerLogs, \"pause\": daemon.ContainerPause, \"resize\": daemon.ContainerResize, \"restart\": daemon.ContainerRestart, \"start\": daemon.ContainerStart, \"stop\": daemon.ContainerStop, \"top\": daemon.ContainerTop, \"unpause\": daemon.ContainerUnpause, \"wait\": daemon.ContainerWait, \"image_delete\": daemon.ImageDelete, // FIXME: see above } { if err := eng.Register(name, method); err != nil { return err } } if err := daemon.Repositories().Install(eng); err != nil { return err } // FIXME: this hack is necessary for legacy integration tests to access // the daemon object. eng.Hack_SetGlobalVar(\"httpapi.daemon\", daemon) return nil } 以上代码的实现分为三部分： 向eng对象中注册众多的Handler对象； daemon.Repositories().Install(eng)实现了向eng对象注册多个与image相关的Handler，Install的实现位于./docker/graph/service.go； eng.Hack_SetGlobalVar(\"httpapi.daemon\", daemon)实现向eng对象中map类型的hack对象中添加一条记录，key为”httpapi.daemon”，value为daemon。 3.6.3. 运行acceptconnections的job /docker/daemon.go if err := eng.Job(\"acceptconnections\").Run(); err != nil { log.Fatal(err) } 在goroutine内部最后运行名为”acceptconnections”的job，主要作用是通知init守护进程，Docker Daemon可以开始接受请求了。 首先执行eng.Job(\"acceptconnections\")，返回一个Job，随后再执行eng.Job(\"acceptconnections\").Run()，也就是该执行Job的run函数。 /engine/engine.go // Job creates a new job which can later be executed. // This function mimics `Command` from the standard os/exec package. func (eng *Engine) Job(name string, args ...string) *Job { job := &Job{ Eng: eng, Name: name, Args: args, Stdin: NewInput(), Stdout: NewOutput(), Stderr: NewOutput(), env: &Env{}, } if eng.Logging { job.Stderr.Add(utils.NopWriteCloser(eng.Stderr)) } // Catchall is shadowed by specific Register. if handler, exists := eng.handlers[name]; exists { job.handler = handler } else if eng.catchall != nil && name != \"\" { // empty job names are illegal, catchall or not. job.handler = eng.catchall } return job } 首先创建一个类型为Job的job对象，该对象中Eng属性为函数的调用者eng，Name属性为”acceptconnections”，没有参数传入。 另外在eng对象所有的handlers属性中寻找键为”acceptconnections”记录的值，由于在加载builtins操作中的remote(eng)中已经向eng注册过这样的一条记录，key为”acceptconnections”，value为apiserver.AcceptConnections。 因此job对象的handler为apiserver.AcceptConnections。 最后返回已经初始化完毕的对象job。 创建完job对象之后，随即执行该job对象的run()函数。 /engine/job.go // A job is the fundamental unit of work in the docker engine. // Everything docker can do should eventually be exposed as a job. // For example: execute a process in a container, create a new container, // download an archive from the internet, serve the http api, etc. // // The job API is designed after unix processes: a job has a name, arguments, // environment variables, standard streams for input, output and error, and // an exit status which can indicate success (0) or error (anything else). // // One slight variation is that jobs report their status as a string. The // string \"0\" indicates success, and any other strings indicates an error. // This allows for richer error reporting. // type Job struct { Eng *Engine Name string Args []string env *Env Stdout *Output Stderr *Output Stdin *Input handler Handler status Status end time.Time } type Status int const ( StatusOK Status = 0 StatusErr Status = 1 StatusNotFound Status = 127 ) // Run executes the job and blocks until the job completes. // If the job returns a failure status, an error is returned // which includes the status. func (job *Job) Run() error { if job.Eng.IsShutdown() { return fmt.Errorf(\"engine is shutdown\") } // FIXME: this is a temporary workaround to avoid Engine.Shutdown // waiting 5 seconds for server/api.ServeApi to complete (which it never will) // everytime the daemon is cleanly restarted. // The permanent fix is to implement Job.Stop and Job.OnStop so that // ServeApi can cooperate and terminate cleanly. if job.Name != \"serveapi\" { job.Eng.l.Lock() job.Eng.tasks.Add(1) job.Eng.l.Unlock() defer job.Eng.tasks.Done() } // FIXME: make this thread-safe // FIXME: implement wait if !job.end.IsZero() { return fmt.Errorf(\"%s: job has already completed\", job.Name) } // Log beginning and end of the job job.Eng.Logf(\"+job %s\", job.CallString()) defer func() { job.Eng.Logf(\"-job %s%s\", job.CallString(), job.StatusString()) }() var errorMessage = bytes.NewBuffer(nil) job.Stderr.Add(errorMessage) if job.handler == nil { job.Errorf(\"%s: command not found\", job.Name) job.status = 127 } else { job.status = job.handler(job) job.end = time.Now() } // Wait for all background tasks to complete if err := job.Stdout.Close(); err != nil { return err } if err := job.Stderr.Close(); err != nil { return err } if err := job.Stdin.Close(); err != nil { return err } if job.status != 0 { return fmt.Errorf(\"%s\", Tail(errorMessage, 1)) } return nil } Run()函数的实现位于./docker/engine/job.go，该函数执行指定的job，并在job执行完成前一直阻塞。对于名为”acceptconnections”的job对象，运行代码为job.status = job.handler(job)，由于job.handler值为apiserver.AcceptConnections，故真正执行的是job.status = apiserver.AcceptConnections(job)。 进入AcceptConnections的具体实现，位于./docker/api/server/server.go,如下： /api/server/server.go func AcceptConnections(job *engine.Job) engine.Status { // Tell the init daemon we are accepting requests go systemd.SdNotify(\"READY=1\") if activationLock != nil { close(activationLock) } return engine.StatusOK } 重点为go systemd.SdNotify(\"READY=1\")的实现，位于./docker/pkg/system/sd_notify.go，主要作用是通知init守护进程Docker Daemon的启动已经全部完成，潜在的功能是使得Docker Daemon开始接受Docker Client发送来的API请求。 至此，已经完成通过goroutine来加载daemon对象并运行。 3.7. 打印Docker版本及驱动信息 显示docker的版本信息，以及ExecDriver和GraphDriver这两个驱动的具体信息 /docker/daemon.go // TODO actually have a resolved graphdriver to show? log.Printf(\"docker daemon: %s %s; execdriver: %s; graphdriver: %s\", dockerversion.VERSION, dockerversion.GITCOMMIT, daemonCfg.ExecDriver, daemonCfg.GraphDriver, ) 3.8. serveapi的创建与运行 打印部分Docker具体信息之后，Docker Daemon立即创建并运行名为”serveapi”的job，主要作用为让Docker Daemon提供API访问服务。 /docker/daemon.go // Serve api job := eng.Job(\"serveapi\", flHosts...) job.SetenvBool(\"Logging\", true) job.SetenvBool(\"EnableCors\", *flEnableCors) job.Setenv(\"Version\", dockerversion.VERSION) job.Setenv(\"SocketGroup\", *flSocketGroup) job.SetenvBool(\"Tls\", *flTls) job.SetenvBool(\"TlsVerify\", *flTlsVerify) job.Setenv(\"TlsCa\", *flCa) job.Setenv(\"TlsCert\", *flCert) job.Setenv(\"TlsKey\", *flKey) job.SetenvBool(\"BufferRequests\", true) if err := job.Run(); err != nil { log.Fatal(err) } 创建一个名为”serveapi”的job，并将flHosts的值赋给job.Args。flHost的作用主要是为Docker Daemon提供使用的协议与监听的地址。 Docker Daemon为该job设置了众多的环境变量，如安全传输层协议的环境变量等。最后通过job.Run()运行该serveapi的job。 由于在eng中key为”serveapi”的handler，value为apiserver.ServeApi，故该job运行时，执行apiserver.ServeApi函数，位于./docker/api/server/server.go。ServeApi函数的作用主要是对于用户定义的所有支持协议，Docker Daemon均创建一个goroutine来启动相应的http.Server，分别为不同的协议服务。具体参考Docker Server。 参考： 《Docker源码分析》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "},"code-analysis/code-analysis-of-docker-server.html":{"url":"code-analysis/code-analysis-of-docker-server.html","title":"Docker Server","keywords":"","body":"1. Docker Server创建流程 Docker Server是Daemon Server的重要组成部分，功能：接收Docker Client发送的请求，并按照相应的路由规则实现请求的路由分发，最终将请求处理的结果返回给Docker Client。 Docker Daemon启动，在mainDaemon()运行的最后创建并运行serverapi的Job，让Docker Daemon提供API访问服务。 Docker Server的整个生命周期 创建Docker Server的Job 配置Job的环境变量 触发执行Job 说明：本文分析的代码为Docker 1.2.0版本。 1.1. 创建“serverapi”的Job /docker/daemon.go func mainDaemon() { ... // Serve api job := eng.Job(\"serveapi\", flHosts...) ... } 运行serverapi的Job时，会执行该Job的处理方法api.ServeApi。 1.2. 配置Job环境变量 /docker/daemon.go job.SetenvBool(\"Logging\", true) job.SetenvBool(\"EnableCors\", *flEnableCors) job.Setenv(\"Version\", dockerversion.VERSION) job.Setenv(\"SocketGroup\", *flSocketGroup) job.SetenvBool(\"Tls\", *flTls) job.SetenvBool(\"TlsVerify\", *flTlsVerify) job.Setenv(\"TlsCa\", *flCa) job.Setenv(\"TlsCert\", *flCert) job.Setenv(\"TlsKey\", *flKey) job.SetenvBool(\"BufferRequests\", true) 参数分为两种 创建Job实例时，用指定参数直接初始化Job的Args属性 创建Job后，给Job添加指定的环境变量 环境变量名 FLAG参数 默认 作用值 Logging true 启用Docker容器的日志输出 EnableCors flEnableCors false 在远程API中提供CORS头 Version 显示Docker版本号 SocketGroup flSockerGroup docker 在daemon模式中unix domain socket分配用户组名 Tls flTls false 使用TLS安全传输协议 TlsVerify flTlsVerify false 使用TLS并验证远程客户端 TlsCa flCa 指定CA文件路径 TlsCert flCert TLS证书文件路径 TlsKey flKey TLS密钥文件路径 BufferRequest true 缓存Docker Client请求 1.3. 运行Job /api/server/server.go if err := job.Run(); err != nil { log.Fatal(err) } Docker在eng对象中注册过键位serverapi的处理方法，在运行Job的时候执行这个处理方法的值函数，相应的处理方法的值为api.ServeApi。 2. ServeApi运行流程 ​ ServeApi属于Docker Server提供API服务的部分，作为一个监听请求、处理请求、响应请求的服务端，支持三种协议：TCP协议、UNIX Socket形式以及fd的形式。功能是：循环检查Docker Daemon支持的所有协议，并为每一种协议创建一个协程goroutine，并在协程内部配置一个服务于HTTP请求的服务端。 /api/server/server.go // ServeApi loops through all of the protocols sent in to docker and spawns // off a go routine to setup a serving http.Server for each. func ServeApi(job *engine.Job) engine.Status { if len(job.Args) == 0 { return job.Errorf(\"usage: %s PROTO://ADDR [PROTO://ADDR ...]\", job.Name) } var ( protoAddrs = job.Args chErrors = make(chan error, len(protoAddrs)) ) activationLock = make(chan struct{}) for _, protoAddr := range protoAddrs { protoAddrParts := strings.SplitN(protoAddr, \"://\", 2) if len(protoAddrParts) != 2 { return job.Errorf(\"usage: %s PROTO://ADDR [PROTO://ADDR ...]\", job.Name) } go func() { log.Infof(\"Listening for HTTP on %s (%s)\", protoAddrParts[0], protoAddrParts[1]) chErrors ServeApi执行流程： 检查Job参数，确保传入参数无误 定义Docker Server的监听协议与地址，以及错误信息管理channel 遍历协议地址，针对协议创建相应的服务端 通过chErrors建立goroutine与主进程之间的协调关系 2.1. 判断Job参数 判断Job参数，job.Args，即数组flHost，若flHost的长度为0，则说明没有监听的协议与地址，参数有误。 /api/server/server.go func ServeApi(job *engine.Job) engine.Status { if len(job.Args) == 0 { return job.Errorf(\"usage: %s PROTO://ADDR [PROTO://ADDR ...]\", job.Name) } ... } 2.2. 定义监听协议与地址及错误信息 /api/server/server.go var ( protoAddrs = job.Args chErrors = make(chan error, len(protoAddrs)) ) activationLock = make(chan struct{}) 定义protoAddrs[flHosts的内容]、chErrors[错误类型管道]与activationLock[同步serveapi和acceptconnections两个job执行的管道]三个变量， 2.3. 遍历协议地址 /api/server/server.go for _, protoAddr := range protoAddrs { protoAddrParts := strings.SplitN(protoAddr, \"://\", 2) if len(protoAddrParts) != 2 { return job.Errorf(\"usage: %s PROTO://ADDR [PROTO://ADDR ...]\", job.Name) } go func() { log.Infof(\"Listening for HTTP on %s (%s)\", protoAddrParts[0], protoAddrParts[1]) chErrors 遍历协议地址，针对协议创建相应的服务端。协议地址 2.4. 协调chErrors与主进程关系 根据chErrors的值运行，如果chErrors这个管道中有错误内容，则ServerApi一次循环结束，若无错误内容，循环被阻塞。即chErrors确保ListenAndServe所对应的协程能和主函数ServeApi进行协调，如果协程出错，主函数ServeApi仍然可以捕获这样的错误，从而导致程序退出。 /api/server/server.go for i := 0; i 3. ListenAndServe实现 ListenAndServe的功能：使Docker Server监听某一指定地址，并接收该地址的请求，并对以上请求路由转发至相应的处理方法处。 ListenAndServe执行流程： 创建route路由实例 创建listener监听实例 创建http.Server 启动API服务 流程图： 3.1. 创建route路由实例 /api/server/server.go // ListenAndServe sets up the required http.Server and gets it listening for // each addr passed in and does protocol specific checking. func ListenAndServe(proto, addr string, job *engine.Job) error { var l net.Listener r, err := createRouter(job.Eng, job.GetenvBool(\"Logging\"), job.GetenvBool(\"EnableCors\"), job.Getenv(\"Version\")) if err != nil { return err } ... } 路由实例的作用：负责Docker Server对外部请求的路由及转发。 实现过程： 创建全新的route路由实例 为route实例添加路由记录 3.1.1. 创建空路由实例 /api/server/server.go func createRouter(eng *engine.Engine, logging, enableCors bool, dockerVersion string) (*mux.Router, error) { r := mux.NewRouter() ... } /vendor/src/github.com/gorilla/mux/mux.go // NewRouter returns a new router instance. func NewRouter() *Router { return &Router{namedRoutes: make(map[string]*Route), KeepContext: false} } // This will send all incoming requests to the router. type Router struct { // Configurable Handler to be used when no route matches. NotFoundHandler http.Handler // Parent route, if this is a subrouter. parent parentRoute // Routes to be matched, in order. routes []*Route // Routes by name for URL building. namedRoutes map[string]*Route // See Router.StrictSlash(). This defines the flag for new routes. strictSlash bool // If true, do not clear the request context after handling the request KeepContext bool } NewRoute()函数返回一个全新的route实例r，类型为mux.Router。实例初始化nameRoutes和KeepContext。 nameRoutes：map类型，key为string类型，value为Route路由记录类型 KeepContext：属性为false，则处理完请求后清除请求内容，不对请求做存储操作 mux.Router会通过一系列已经注册过的路由记录，来匹配接收的请求。先通过请求的URL或者其他条件找到相应的路由记录，并调用这条记录中的执行处理方法。 mux.Router特性 请求可以基于URL的主机名、路径、路径前缀、shemes、请求头和请求值、HTTP请求方法类型或者使用自定义的匹配规则 URL主机名和路径可以通过一个正则表达式来表示 注册的URL可以直接被运用，也可以保留从而保证维护资源的使用 路由记录同样看可以作用于子路由记录 3.1.2. 添加路由记录 /api/server/server.go if os.Getenv(\"DEBUG\") != \"\" { AttachProfiler(r) } m := map[string]map[string]HttpApiFunc{ \"GET\": { \"/_ping\": ping, \"/events\": getEvents, \"/info\": getInfo, \"/version\": getVersion, \"/images/json\": getImagesJSON, \"/images/viz\": getImagesViz, \"/images/search\": getImagesSearch, \"/images/{name:.*}/get\": getImagesGet, \"/images/{name:.*}/history\": getImagesHistory, \"/images/{name:.*}/json\": getImagesByName, \"/containers/ps\": getContainersJSON, \"/containers/json\": getContainersJSON, \"/containers/{name:.*}/export\": getContainersExport, \"/containers/{name:.*}/changes\": getContainersChanges, \"/containers/{name:.*}/json\": getContainersByName, \"/containers/{name:.*}/top\": getContainersTop, \"/containers/{name:.*}/logs\": getContainersLogs, \"/containers/{name:.*}/attach/ws\": wsContainersAttach, }, \"POST\": { \"/auth\": postAuth, \"/commit\": postCommit, \"/build\": postBuild, \"/images/create\": postImagesCreate, \"/images/load\": postImagesLoad, \"/images/{name:.*}/push\": postImagesPush, \"/images/{name:.*}/tag\": postImagesTag, \"/containers/create\": postContainersCreate, \"/containers/{name:.*}/kill\": postContainersKill, \"/containers/{name:.*}/pause\": postContainersPause, \"/containers/{name:.*}/unpause\": postContainersUnpause, \"/containers/{name:.*}/restart\": postContainersRestart, \"/containers/{name:.*}/start\": postContainersStart, \"/containers/{name:.*}/stop\": postContainersStop, \"/containers/{name:.*}/wait\": postContainersWait, \"/containers/{name:.*}/resize\": postContainersResize, \"/containers/{name:.*}/attach\": postContainersAttach, \"/containers/{name:.*}/copy\": postContainersCopy, }, \"DELETE\": { \"/containers/{name:.*}\": deleteContainers, \"/images/{name:.*}\": deleteImages, }, \"OPTIONS\": { \"\": optionsHandler, }, } m的类型为映射，key表示HTTP的请求类型，如GET、POST、DELETE等，value为映射类型，代表URL与执行处理方法的映射。 /api/server/server.go type HttpApiFunc func(eng *engine.Engine, version version.Version, w http.ResponseWriter, r *http.Request, vars map[string]string) error 3.2. 创建listener监听实例 路由模块完成请求的路由与分发，监听模块完成请求的监听功能。Listener是一种面向流协议的通用网络监听模块。 /api/server/server.go var l net.Listener ... if job.GetenvBool(\"BufferRequests\") { l, err = listenbuffer.NewListenBuffer(proto, addr, activationLock) } else { l, err = net.Listen(proto, addr) Listenbuffer的作用：让Docker Server立即监听指定协议地址上的请求，但将这些请求暂时先缓存下来，等Docker Daemon全部启动完毕之后才让Docker Server开始接受这些请求。 /pkg/listenbuffer/buffer.go // NewListenBuffer returns a listener listening on addr with the protocol. func NewListenBuffer(proto, addr string, activate chan struct{}) (net.Listener, error) { wrapped, err := net.Listen(proto, addr) if err != nil { return nil, err } return &defaultListener{ wrapped: wrapped, activate: activate, }, nil } 若协议类型为TCP，Job环境变量中Tls或TlsVerity有一个为true，则说明Docker Server需要支持HTTPS服务。需要建立一个tls.Config类型实例tlsConfig，在tlsConfig中加载证书、认证信息，通过tls包中的NewListener函数创建HTTPS协议请求的Listener实例。 /api/server/server.go l = tls.NewListener(l, tlsConfig) 3.3. 创建http.Server /api/server/server.go httpSrv := http.Server{Addr: addr, Handler: r} Docker Server需要创建一个Server对象来运行HTTP/HTTPS服务端，创建http.Server，addr为需要监听的地址，r为mux.Router。 3.4. 启动API服务 创建http.Server实例后，即启动API服务，监听请求，并对每一个请求生成一个新的协程来做专属服务。对于每个请求，协程会读取请求，查询路由表中的路由记录项，找到匹配的路由记录，最终调用路由记录中的处理方法，执行完毕返回响应信息。 /api/server/server.go return httpSrv.Serve(l) 参考： 《Docker源码分析》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2021-03-04 18:07:14 "}}